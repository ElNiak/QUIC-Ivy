#lang ivy1.7

include order
include quic_infer
include file
include quic_shim_server
include quic_locale
include quic_server


# This is a simple tester for quic servers. The tester plays the role of a
# single client, which may use multiple UDP ports.
#
# Compile the tester like this:
#
#     ivyc target=test quic_server_test.ivy
#
# Run it like this:
#
#     ./quic_server_test [parameter=value...]
#
# Parameters are:
#
#     the_cid:int      cid to be used by the client (default 0xd)
#     client_addr:int  the client IP address (default 0x7f000001, i.e., the loopback interface)
#     server_addr:int  the server IP address (default 0x7f000001, i.e., the loopback interface)
#     server_port:int  the server port number (default 4443)
#     server_cid:int   the initial server CID used by the client (default 0xb)
#     client_port:int  the client port number (default 4987)
#     client_port_alt:int     the alternate client port (for migration) (default 4988)
#     max_stream_data:int     the initial max stream data (0x2000)
#
#
# Notes:
#
# - All IP addresses are IPv4 and are given as single 32-bit numbers,
#   rather than using the dot notation.
#
#

# The command-line parameters, with their defaults

#
# Restrict generation to packets from the designated client endpoints
# to the server endpoint.
#

# An endpoint MUST NOT initiate
#   connection migration before the handshake is confirmed, as defined in
#   section 4.1.2 of [QUIC-TLS].

var allowed_multiple_migration : bool

after init {
	allowed_multiple_migration := true
}

before packet_event(src:ip.endpoint,dst:ip.endpoint,pkt:quic_packet) {
    if _generating {
        var tp := trans_params(the_cid);
        if ~disable_active_migration.is_set(tp) {
            if ~migration_done | allowed_multiple_migration { #only one migration
                require src = client.ep | src = client_alt;
            } else {
                require src = client_alt;
            }
        } else {
            require src = client.ep;
        };
        require dst = server.ep;
        require pkt.token.end = 0; 
    };
    require pkt.long -> pkt.pversion = 0xff00001d  #version 29
}

# The protocol specification describes all the events occurring the
# system at all protocol layers. When constructing the test mirror,
# however, we need to generate only events that are outputs of the
# environment. Ivy doesn't have any built-in mechanism to do this,
# so we have to add a constraint to every generated action. 
#
# We also add other pre-conditions to the actions to try to restrict
# them to relevant parameter values. 
#
# To restrict the generated events, we use the built-in predicate
# "_generating" that is true if this is a generated event.
#
# This is the mirror constraint for the stream frame protocol. We add
# some requirements to make the tests more interesting. In particular,
# we don't want the tester to produce lots of tiny frames (or empty
# ones) so we require that a stream frame send all of the available
# stream data. 
#
# TODO: We reuquire tje `off` and `len` bits to be true. Maybe these should
# determined in the low-level packet encoding stage.

before frame.stream.handle(f:frame.stream,scid:cid,dcid:cid,e:quic_packet_type) {
    if _generating {
        require scid = the_cid;
        require connected(the_cid) & dcid = connected_to(the_cid);
        require f.len & f.off; 
        require f.length > 0;
        require f.offset = stream_length(dcid,f.id);
        require f.length = (stream_app_data_end(dcid,f.id)) - f.offset;
    };

}

# We have something similar for crypto frames

before frame.crypto.handle(f:frame.crypto,scid:cid,dcid:cid,e:quic_packet_type) {
    if _generating {
        require scid = the_cid;
        require f.length > 0;
        require f.offset = crypto_length(scid,e);
        require f.length = (crypto_data_end(scid,e)) - f.offset;
    }
}

# Generate ack frames only for the client. HACK: to avoid generating
# blizzards of ACK's, we set the bit `force_new_ack` which forces
# ACK's to have at least on previously unacked sequenc number. There
# should be a better way to do this.

before frame.ack.handle(f:frame.ack,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        force_new_ack := true;
        #call handle_sending_ack(f.largest_acked);
    } 
}

# Generate rst_stream frames only for the environment process(es).

before frame.rst_stream.handle(f:frame.rst_stream,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate stop_sending frames only for the environment process(es).

before frame.stop_sending.handle(f:frame.stop_sending,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate max_streams frames only for the environment process(es).

before frame.max_streams.handle(f:frame.max_streams,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}

before frame.new_connection_id.handle(f:frame.new_connection_id,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}


before frame.retire_connection_id.handle(f:frame.retire_connection_id,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}


# Generate connection_close frames only for the environment process(es).
#
# Note: requiring the `err_code` is zero on non-generated frames means that
# we stop the test if the peer reports a protocol error. 

before frame.connection_close.handle(f:frame.connection_close,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    } else {
        require is_no_error
    }
}

# Generate application_close frames only for the environment process(es).

before frame.application_close.handle(f:frame.application_close,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}

# Generate max_stream_data frames only for the environment process(es), and only for
# a restricted range of frames (so we don't throttle all of the data).

before frame.max_stream_data.handle(f:frame.max_stream_data,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require 4 <= f.id & f.id <= 16;
    }
}

# Generate stream_data_blocked frames only for the environment process(es).
# We restrict the frame id.

before frame.stream_data_blocked.handle(f:frame.stream_data_blocked,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate max_data frames only for the environment process(es). Here, for
# non-generated frames, we check that the max_data value doesn't decrease.
# This is not forbidden, but it seems like a good thing to check.

before frame.max_data.handle(f:frame.max_data,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.pos = 4000;
    }
    else {
        require ~(max_data_set(scid) & max_data_val(scid) > f.pos);
        var tp := trans_params(scid);
        if initial_max_data.is_set(tp) {
# TEMORARY: commented out until fixed
#            require initial_max_data.value(tp).stream_pos_32 <= f.pos;
        }
    }
}

# This is where we restrict the client to send only a specific HTTP
# request.  We allow generating application data at the client end
# only if the previous data have not been sent. This is to avoid
# building up a long queue. We only send the http request data read
# from the input file, up to the first newline. We restrict the client
# to use stream id's from 4 to 60 in increments of 4.

action client_send_event(src:ip.endpoint, dst:ip.endpoint, dcid:cid, s : stream_id, end : stream_pos)

var current_stream : stream_id

after init {
    current_stream := 4
}

around client_send_event {
    require s = current_stream;
    var tp := trans_params(the_cid);
    if ~disable_active_migration.is_set(tp) {
	 if ~migration_done | allowed_multiple_migration  { #only one migration
        	 require src = client.ep | src = client_alt;
	 } else {
		 require src = client_alt;
	 }
    } else {
	require src = client.ep;
    };

    require dst = server.ep;
    require connected(the_cid) & dcid = connected_to(the_cid);
    require stream_length(dcid,s) = stream_app_data_end(dcid,s);
    require stream_length(dcid,s) < end & end <= http_request.end;
    require current_stream < 60;
    ...
    while end < http_request.end & http_request.value(end) ~= 10 {
        end := end.next
    };
    if end < http_request.end {
        end := end.next
    };
    var data := http_request.segment(stream_length(dcid,s),end);
#    call app_send_event(src,dst,dcid,s,data,end = http_request.end);
    call app_send_event(src,dst,dcid,s,data,stream_length(dcid,s),true);
    current_stream := current_stream + 4;
}

# The actions listed below will be generated by the mirror.
#
# Note: some of these are commented out. They are added in other files
# that include this one.

export frame.ack.handle
export frame.stream.handle
export frame.crypto.handle
export frame.path_response.handle
export packet_event
export client_send_event
export tls_recv_event
#export frame.new_connection_id.handle
#export frame.retire_connection_id.handle
#export frame.rst_stream.handle
#export frame.max_stream_id.handle
#export frame.connection_close.handle
#export frame.max_stream_data.handle
#export frame.max_data.handle

# Final check
#
# When the test is complete, the tester calls the special action `_finalize`.
# We use this action to make some heuristic checks, for example that some
# data was actually received from the server. We can add advice to this
# action with additional checks.

export action _finalize = {
    # chris TODO 
    require conn_total_data(the_cid) > 0;
}

