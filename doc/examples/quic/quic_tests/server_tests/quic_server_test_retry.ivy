#lang ivy1.7

include order
include quic_infer
include file
include quic_shim_server
include quic_locale
include quic_server

#
# We fix the initial transport parameters here. TODO: In principle these
# parameters should be selected randomly by some event.
#

include quic_server_standard_tp

after init {
    sock := net.open(endpoint_id.client,client.ep);
    sock_alt := net.open(endpoint_id.client_alt,client_alt);
    sock_vn := sock; # net.open(endpoint_id.client_vn,client_vn);
    client.tls_id := 0;
    server.tls_id := 1;
    var extns := tls_extensions.empty;
    extns := extns.append(make_transport_parameters);
    call tls_api.upper.create(0,false,extns);  # false means this instance of tls is not a server
}


after init {
	allowed_multiple_migration := false;
    allowed_migration := false;
    version_negociated := false;
    initial_version := 0xff00001c;
}

after init {
    supported_versions := versions.empty;
    var v1 := stream_data.empty;
    v1 := v1.append(0xff);
    v1 := v1.append(0x0);
    v1 := v1.append(0x0);
    v1 := v1.append(0x1c); # TODO
    supported_versions := supported_versions.append(v1);

    supported_versions_bv := versions_bv.empty;
    supported_versions_bv := supported_versions_bv.append(0xff00001c);
}

# This token MUST be repeated by the client in all
#    Initial packets it sends for that connection after it receives the
#    Retry packet. 

# In comparison, a
#    token obtained in a Retry packet MUST be used immediately during the
#    connection attempt and cannot be used in subsequent connection
#    attempts.

# A client MUST
#    discard a Retry packet that contains a Source Connection ID field
#    that is identical to the Destination Connection ID field of its
#    Initial packet TODO

# The client MUST use the value from the Source
#    Connection ID field of the Retry packet in the Destination Connection
#    ID field of subsequent packets that it sends.

before packet_event(src:ip.endpoint,dst:ip.endpoint,pkt:quic_packet) {
    if _generating {
        var tp := trans_params(the_cid);
        if version_negociated {
            require src = client_vn;
        } else {
            if ~disable_active_migration.is_set(tp) & allowed_migration {
                if ~migration_done | allowed_multiple_migration { 
                    # only one migration
                    require src = client.ep | src = client_alt;
                } else {
                    require src = client_alt;
                }
            } else {
                require src = client.ep;
            }
        };
        if pkt.ptype = quic_packet_type.initial {
            pkt.dst_cid := server_cid; # TODO
        };
        require dst = server.ep;
        if pkt.ptype = quic_packet_type.initial & retry_recv & ~zero_length_token {
            require pkt.token = retry_recv_token;
        } else {
            require pkt.token.end = 0; 
        };
        
    };
    if final_version = 0x00000000 {
        #require pkt.long -> pkt.pversion = 0xff00001d  #version 29
        #require pkt.long -> pkt.pversion = 0xff000020  #version 32
        #require pkt.long -> pkt.pversion = 0xff00001e  #version 30
        require pkt.long -> pkt.pversion = initial_version  #version 30
    } else {
        require pkt.long -> pkt.pversion = final_version
    };
}

# The protocol specification describes all the events occurring the
# system at all protocol layers. When constructing the test mirror,
# however, we need to generate only events that are outputs of the
# environment. Ivy doesn't have any built-in mechanism to do this,
# so we have to add a constraint to every generated action. 
#
# We also add other pre-conditions to the actions to try to restrict
# them to relevant parameter values. 
#
# To restrict the generated events, we use the built-in predicate
# "_generating" that is true if this is a generated event.
#
# This is the mirror constraint for the stream frame protocol. We add
# some requirements to make the tests more interesting. In particular,
# we don't want the tester to produce lots of tiny frames (or empty
# ones) so we require that a stream frame send all of the available
# stream data. 
#
# TODO: We reuquire tje `off` and `len` bits to be true. Maybe these should
# determined in the low-level packet encoding stage.

before frame.stream.handle(f:frame.stream,scid:cid,dcid:cid,e:quic_packet_type) {
    if _generating {
        require scid = the_cid;
        require connected(the_cid) & dcid = connected_to(the_cid);
        require f.len & f.off; 
        require f.length > 0;
        require f.offset = stream_length(dcid,f.id);
        require f.length = (stream_app_data_end(dcid,f.id)) - f.offset;
    };

}

# We have something similar for crypto frames

before frame.crypto.handle(f:frame.crypto,scid:cid,dcid:cid,e:quic_packet_type) {
    if _generating {
        require scid = the_cid;
        require f.length > 0;
        call show_crypto_length(crypto_length(scid,e));
        if e = quic_packet_type.initial & false {
            require f.offset = 0;
        } else {
            require f.offset = crypto_length(scid,e);
        };
        require f.length = (crypto_data_end(scid,e)) - f.offset;
    }
}



# Generate ack frames only for the client. HACK: to avoid generating
# blizzards of ACK's, we set the bit `force_new_ack` which forces
# ACK's to have at least on previously unacked sequenc number. There
# should be a better way to do this.

before frame.ack.handle(f:frame.ack,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        force_new_ack := true;
        #call handle_sending_ack(f.largest_acked);
    } 
}

before frame.new_token.handle(f:frame.new_token,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        #call handle_sending_ack(f.largest_acked);
    } else {
        call tls_api.upper.save_token(f.data);
    }
}

# Generate rst_stream frames only for the environment process(es).

before frame.rst_stream.handle(f:frame.rst_stream,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate stop_sending frames only for the environment process(es).

before frame.stop_sending.handle(f:frame.stop_sending,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate max_streams frames only for the environment process(es).

before frame.max_streams.handle(f:frame.max_streams,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}

before frame.new_connection_id.handle(f:frame.new_connection_id,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}


before frame.retire_connection_id.handle(f:frame.retire_connection_id,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    }
}


# Generate connection_close frames only for the environment process(es).
#
# Note: requiring the `err_code` is zero on non-generated frames means that
# we stop the test if the peer reports a protocol error. 

before frame.connection_close.handle(f:frame.connection_close,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require conn_total_data(the_cid) > 100; # tricks
        require f.err_code = 0;
    } else {
        require is_no_error;
        call _finalize;
    }
}

# Generate application_close frames only for the environment process(es).

before frame.application_close.handle(f:frame.application_close,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
    } else {
        require is_no_error;
        call _finalize;
    }
}

# Generate max_stream_data frames only for the environment process(es), and only for
# a restricted range of frames (so we don't throttle all of the data).

before frame.max_stream_data.handle(f:frame.max_stream_data,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require 4 <= f.id & f.id <= 16;
    }
}

# Generate stream_data_blocked frames only for the environment process(es).
# We restrict the frame id.

before frame.stream_data_blocked.handle(f:frame.stream_data_blocked,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.id = 4;
    }
}

# Generate max_data frames only for the environment process(es). Here, for
# non-generated frames, we check that the max_data value doesn't decrease.
# This is not forbidden, but it seems like a good thing to check.

before frame.max_data.handle(f:frame.max_data,scid:cid,dcid:cid) {
    if _generating {
        require scid = the_cid;
        require f.pos = 4000;
    }
    else {
        require ~(max_data_set(scid) & max_data_val(scid) > f.pos);
        var tp := trans_params(scid);
        if initial_max_data.is_set(tp) {
# TEMORARY: commented out until fixed
#            require initial_max_data.value(tp).stream_pos_32 <= f.pos;
        }
    }
}

# This is where we restrict the client to send only a specific HTTP
# request.  We allow generating application data at the client end
# only if the previous data have not been sent. This is to avoid
# building up a long queue. We only send the http request data read
# from the input file, up to the first newline. We restrict the client
# to use stream id's from 4 to 60 in increments of 4.

action client_send_event(src:ip.endpoint, dst:ip.endpoint, dcid:cid, s : stream_id, end : stream_pos)

var current_stream : stream_id

after init {
    current_stream := 4
}

around client_send_event {
    require s = current_stream;
    var tp := trans_params(the_cid);

    if version_negociated {
        require src = client_vn;
    } else {
        if ~disable_active_migration.is_set(tp) {
            if ~migration_done | allowed_multiple_migration  { #only one migration
                require src = client.ep | src = client_alt;
            } else {
                require src = client_alt;
            }
        } else {
            require src = client.ep;
        }
    };

    require dst = server.ep;
    require connected(the_cid) & dcid = connected_to(the_cid);
    require stream_length(dcid,s) = stream_app_data_end(dcid,s);
    require stream_length(dcid,s) < end & end <= http_request.end;
    require current_stream < 60;
    ...
    while end < http_request.end & http_request.value(end) ~= 10 {
        end := end.next
    };
    if end < http_request.end {
        end := end.next
    };
    var data := http_request.segment(stream_length(dcid,s),end);
#    call app_send_event(src,dst,dcid,s,data,end = http_request.end);
    call app_send_event(src,dst,dcid,s,data,stream_length(dcid,s),true);
    current_stream := current_stream + 4;
}

# The actions listed below will be generated by the mirror.
#
# Note: some of these are commented out. They are added in other files
# that include this one.

export frame.ack.handle
export frame.stream.handle
export frame.crypto.handle
export frame.path_response.handle
export packet_event
export client_send_event
export tls_recv_event
#export frame.new_connection_id.handle
#export frame.retire_connection_id.handle
#export frame.rst_stream.handle
#export frame.max_stream_id.handle
export frame.connection_close.handle
#export frame.max_stream_data.handle
#export frame.max_data.handle
attribute frame.crypto.handle.weight = "5"
attribute frame.path_response.handle.weight = "5"

# Final check
#
# When the test is complete, the tester calls the special action `_finalize`.
# We use this action to make some heuristic checks, for example that some
# data was actually received from the server. We can add advice to this
# action with additional checks.

export action _finalize = {
    # chris TODO 
    require conn_total_data(the_cid) > 0;
}

